{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmxoYFUh3Ldl",
        "outputId": "6baf3a08-e1fc-4ba6-c857-87299ea29ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "datapath = '/content/drive/MyDrive/NLP/singapore_airlines_reviews.csv'\n",
        "\n",
        "df = pd.read_csv(datapath)\n",
        "print(df.head())\n",
        "df.dropna(subset=['text', 'rating'], inplace=True)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT-Vs5IR3XP8",
        "outputId": "81f8da05-fe64-46a8-c325-7aba1393d1c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              published_date published_platform  rating    type  \\\n",
            "0  2024-03-12T14:41:14-04:00            Desktop       3  review   \n",
            "1  2024-03-11T19:39:13-04:00            Desktop       5  review   \n",
            "2  2024-03-11T12:20:23-04:00            Desktop       1  review   \n",
            "3  2024-03-11T07:12:27-04:00            Desktop       5  review   \n",
            "4  2024-03-10T05:34:18-04:00            Desktop       2  review   \n",
            "\n",
            "                                                text  \\\n",
            "0  We used this airline to go from Singapore to L...   \n",
            "1  The service on Singapore Airlines Suites Class...   \n",
            "2  Booked, paid and received email confirmation f...   \n",
            "3  Best airline in the world, seats, food, servic...   \n",
            "4  Premium Economy Seating on Singapore Airlines ...   \n",
            "\n",
            "                                               title  helpful_votes  \n",
            "0                                                 Ok              0  \n",
            "1  The service in Suites Class makes one feel lik...              0  \n",
            "2                         Donâ€™t give them your money              0  \n",
            "3                          Best Airline in the World              0  \n",
            "4  Premium Economy Seating on Singapore Airlines ...              0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "df['title'] = df['title'].fillna('')\n",
        "df['text'] = df['text'].fillna('')\n",
        "df['title'] = df['title'].astype(str).apply(preprocess_text)\n",
        "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
        "df['cleaned_title'] = df['title'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "1snhPPtr3_u5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path = '/content/drive/MyDrive/NLP/glove.6B.100d.txt'  # Path to your GloVe file\n",
        "glove_model = {}\n",
        "with open(glove_path, 'r', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_model[word] = vector"
      ],
      "metadata": {
        "id": "mX5fBrpw49R4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "df['combined_text'] = df['cleaned_text'] + \" \" + df['cleaned_title']\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['combined_text'])\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "def prepare_text(df, column, tokenizer, max_length):\n",
        "    sequences = tokenizer.texts_to_sequences(df[column])\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "    return padded_sequences"
      ],
      "metadata": {
        "id": "kKfaxudj5L-4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
        "from tensorflow.keras.initializers import Constant\n",
        "import numpy as np\n",
        "\n",
        "max_length_text = 100\n",
        "max_length_title = 20\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_model.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_matrix = embedding_matrix.astype(np.float32)\n",
        "\n",
        "print(\"Type of embedding_matrix:\", type(embedding_matrix))\n",
        "print(\"Shape of embedding_matrix:\", embedding_matrix.shape)\n",
        "print(\"Dtype of embedding_matrix:\", embedding_matrix.dtype)\n",
        "print(\"Type of word_index:\", type(word_index))\n",
        "print(\"Length of word_index:\", len(word_index))\n",
        "print(\"Input dimensions:\", len(word_index) + 1, embedding_dim)\n",
        "\n",
        "assert embedding_matrix.shape == (len(word_index) + 1, embedding_dim), \"Embedding matrix shape is incorrect.\"\n",
        "\n",
        "assert embedding_matrix.dtype == np.float32, \"Embedding matrix dtype is incorrect.\"\n",
        "\n",
        "text_input = Input(shape=(max_length_text,), name='text_input')\n",
        "title_input = Input(shape=(max_length_title,), name='title_input')\n",
        "\n",
        "try:\n",
        "    embedding_layer_text = Embedding(\n",
        "        input_dim=len(word_index) + 1,\n",
        "        output_dim=embedding_dim,\n",
        "        embeddings_initializer=Constant(embedding_matrix),\n",
        "        trainable=False\n",
        "    )\n",
        "    embedding_layer_title = Embedding(\n",
        "        input_dim=len(word_index) + 1,\n",
        "        output_dim=embedding_dim,\n",
        "        embeddings_initializer=Constant(embedding_matrix),\n",
        "        trainable=False\n",
        "    )\n",
        "    print(\"Embedding layers created successfully.\")\n",
        "except ValueError as e:\n",
        "    print(\"Error creating embedding layer:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sKdro3K6mHk",
        "outputId": "aa9f334a-716f-4e49-8391-ecfe5dabad0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of embedding_matrix: <class 'numpy.ndarray'>\n",
            "Shape of embedding_matrix: (17590, 100)\n",
            "Dtype of embedding_matrix: float32\n",
            "Type of word_index: <class 'dict'>\n",
            "Length of word_index: 17589\n",
            "Input dimensions: 17590 100\n",
            "Embedding layers created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed the inputs\n",
        "text_embedding = embedding_layer_text(text_input)\n",
        "title_embedding = embedding_layer_title(title_input)\n",
        "\n",
        "# Define LSTM layers\n",
        "text_lstm = LSTM(100)(text_embedding)\n",
        "title_lstm = LSTM(100)(title_embedding)\n",
        "\n",
        "# Concatenate the LSTM outputs\n",
        "concat = Concatenate()([text_lstm, title_lstm])\n",
        "\n",
        "# Add a dense layer and output layer\n",
        "dense = Dense(64, activation='relu')(concat)\n",
        "output = Dense(1, activation='linear')(dense)  # Assuming regression for ratings\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=[text_input, title_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44a8UgNA8AvZ",
        "outputId": "bf7d197f-0211-43d8-cb61-96c9f4db0ce9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text_input (InputLayer)     [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " title_input (InputLayer)    [(None, 20)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 100, 100)             1759000   ['text_input[0][0]']          \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 20, 100)              1759000   ['title_input[0][0]']         \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 100)                  80400     ['embedding[1][0]']           \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               (None, 100)                  80400     ['embedding_1[1][0]']         \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 200)                  0         ['lstm_2[0][0]',              \n",
            " )                                                                   'lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 64)                   12864     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 1)                    65        ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3691729 (14.08 MB)\n",
            "Trainable params: 173729 (678.63 KB)\n",
            "Non-trainable params: 3518000 (13.42 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare sequences for text and title\n",
        "text_sequences = prepare_text(df, 'cleaned_text', tokenizer, max_length_text)\n",
        "title_sequences = prepare_text(df, 'cleaned_title', tokenizer, max_length_title)\n",
        "\n",
        "history = model.fit({'text_input': text_sequences, 'title_input': title_sequences}, df['rating'], epochs=100, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmsd4J_N-agH",
        "outputId": "edb74b30-817d-43d7-d778-ee1deaf86b49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 33s 115ms/step - loss: 1.9186 - mae: 1.0035 - val_loss: 0.7245 - val_mae: 0.6199\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 25s 98ms/step - loss: 0.9284 - mae: 0.7104 - val_loss: 0.6923 - val_mae: 0.5592\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 27s 107ms/step - loss: 0.8619 - mae: 0.6759 - val_loss: 0.6107 - val_mae: 0.5716\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 27s 108ms/step - loss: 0.6782 - mae: 0.5946 - val_loss: 0.6716 - val_mae: 0.5822\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 25s 99ms/step - loss: 0.5476 - mae: 0.5316 - val_loss: 0.4931 - val_mae: 0.5178\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 26s 104ms/step - loss: 0.4905 - mae: 0.4995 - val_loss: 0.4953 - val_mae: 0.5567\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 27s 108ms/step - loss: 0.4413 - mae: 0.4741 - val_loss: 0.4883 - val_mae: 0.4763\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 28s 111ms/step - loss: 0.4192 - mae: 0.4594 - val_loss: 0.4341 - val_mae: 0.4736\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 24s 98ms/step - loss: 0.3896 - mae: 0.4451 - val_loss: 0.4822 - val_mae: 0.5444\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 27s 110ms/step - loss: 0.3551 - mae: 0.4261 - val_loss: 0.4494 - val_mae: 0.4990\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 27s 108ms/step - loss: 0.3232 - mae: 0.4067 - val_loss: 0.4708 - val_mae: 0.4896\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 28s 111ms/step - loss: 0.3058 - mae: 0.3928 - val_loss: 0.4773 - val_mae: 0.5188\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 25s 100ms/step - loss: 0.2731 - mae: 0.3712 - val_loss: 0.4983 - val_mae: 0.5075\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 26s 105ms/step - loss: 0.2525 - mae: 0.3611 - val_loss: 0.4724 - val_mae: 0.4748\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 27s 108ms/step - loss: 0.2324 - mae: 0.3441 - val_loss: 0.6354 - val_mae: 0.5618\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 25s 99ms/step - loss: 0.2477 - mae: 0.3586 - val_loss: 0.5058 - val_mae: 0.5043\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 26s 106ms/step - loss: 0.2089 - mae: 0.3264 - val_loss: 0.5210 - val_mae: 0.5083\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 27s 108ms/step - loss: 0.1914 - mae: 0.3106 - val_loss: 0.5761 - val_mae: 0.5327\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 28s 111ms/step - loss: 0.1695 - mae: 0.2871 - val_loss: 0.5437 - val_mae: 0.4904\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 29s 114ms/step - loss: 0.1704 - mae: 0.2900 - val_loss: 0.4764 - val_mae: 0.4643\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 27s 106ms/step - loss: 0.1532 - mae: 0.2718 - val_loss: 0.4768 - val_mae: 0.4872\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 27s 109ms/step - loss: 0.1382 - mae: 0.2585 - val_loss: 0.5046 - val_mae: 0.4989\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 25s 98ms/step - loss: 0.1432 - mae: 0.2627 - val_loss: 0.5377 - val_mae: 0.5070\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 26s 103ms/step - loss: 0.1255 - mae: 0.2428 - val_loss: 0.4945 - val_mae: 0.4657\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 26s 105ms/step - loss: 0.1190 - mae: 0.2344 - val_loss: 0.4938 - val_mae: 0.4808\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 24s 97ms/step - loss: 0.1108 - mae: 0.2242 - val_loss: 0.6131 - val_mae: 0.5065\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 26s 105ms/step - loss: 0.1026 - mae: 0.2128 - val_loss: 0.5449 - val_mae: 0.4711\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 26s 104ms/step - loss: 0.1007 - mae: 0.2118 - val_loss: 0.5055 - val_mae: 0.4847\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 25s 100ms/step - loss: 0.0949 - mae: 0.2029 - val_loss: 0.5481 - val_mae: 0.4926\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 27s 109ms/step - loss: 0.0878 - mae: 0.1966 - val_loss: 0.5556 - val_mae: 0.4948\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 29s 115ms/step - loss: 0.0830 - mae: 0.1871 - val_loss: 0.5382 - val_mae: 0.4794\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 24s 96ms/step - loss: 0.0801 - mae: 0.1845 - val_loss: 0.5619 - val_mae: 0.4786\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 25s 98ms/step - loss: 0.0781 - mae: 0.1805 - val_loss: 0.5461 - val_mae: 0.4610\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 27s 107ms/step - loss: 0.0725 - mae: 0.1722 - val_loss: 0.5071 - val_mae: 0.4681\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 24s 95ms/step - loss: 0.1437 - mae: 0.2527 - val_loss: 0.5102 - val_mae: 0.4878\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 25s 99ms/step - loss: 0.0915 - mae: 0.2000 - val_loss: 0.5455 - val_mae: 0.4767\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 26s 105ms/step - loss: 0.0717 - mae: 0.1707 - val_loss: 0.5398 - val_mae: 0.4937\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 23s 93ms/step - loss: 0.0639 - mae: 0.1610 - val_loss: 0.5488 - val_mae: 0.5145\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 25s 99ms/step - loss: 0.0573 - mae: 0.1485 - val_loss: 0.4981 - val_mae: 0.4721\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 23s 92ms/step - loss: 0.0557 - mae: 0.1448 - val_loss: 0.5496 - val_mae: 0.5181\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 24s 95ms/step - loss: 0.0574 - mae: 0.1487 - val_loss: 0.5556 - val_mae: 0.4804\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 24s 96ms/step - loss: 0.0514 - mae: 0.1377 - val_loss: 0.5518 - val_mae: 0.4702\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 23s 92ms/step - loss: 0.0490 - mae: 0.1345 - val_loss: 0.5415 - val_mae: 0.4901\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 25s 99ms/step - loss: 0.0439 - mae: 0.1260 - val_loss: 0.5239 - val_mae: 0.4802\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 23s 93ms/step - loss: 0.0452 - mae: 0.1289 - val_loss: 0.5949 - val_mae: 0.4814\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 26s 102ms/step - loss: 0.0406 - mae: 0.1196 - val_loss: 0.5718 - val_mae: 0.4777\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 26s 105ms/step - loss: 0.0438 - mae: 0.1258 - val_loss: 0.5778 - val_mae: 0.4679\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 23s 92ms/step - loss: 0.0423 - mae: 0.1238 - val_loss: 0.5701 - val_mae: 0.4758\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 26s 102ms/step - loss: 0.0402 - mae: 0.1192 - val_loss: 0.5591 - val_mae: 0.4957\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 26s 105ms/step - loss: 0.0402 - mae: 0.1227 - val_loss: 0.5111 - val_mae: 0.4756\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 23s 93ms/step - loss: 0.0386 - mae: 0.1208 - val_loss: 0.5398 - val_mae: 0.4728\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 25s 102ms/step - loss: 0.0382 - mae: 0.1155 - val_loss: 0.5513 - val_mae: 0.4631\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 24s 96ms/step - loss: 0.0410 - mae: 0.1261 - val_loss: 0.5309 - val_mae: 0.4814\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 24s 97ms/step - loss: 0.0332 - mae: 0.1052 - val_loss: 0.5429 - val_mae: 0.4988\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 25s 102ms/step - loss: 0.0316 - mae: 0.1061 - val_loss: 0.5671 - val_mae: 0.5157\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 23s 92ms/step - loss: 0.0316 - mae: 0.1069 - val_loss: 0.5569 - val_mae: 0.4630\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 25s 100ms/step - loss: 0.0343 - mae: 0.1105 - val_loss: 0.5463 - val_mae: 0.4667\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 24s 97ms/step - loss: 0.0296 - mae: 0.0998 - val_loss: 0.5363 - val_mae: 0.4648\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 24s 94ms/step - loss: 0.0310 - mae: 0.1046 - val_loss: 0.5590 - val_mae: 0.4696\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 25s 100ms/step - loss: 0.0284 - mae: 0.0981 - val_loss: 0.5667 - val_mae: 0.4698\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 24s 94ms/step - loss: 0.0269 - mae: 0.0961 - val_loss: 0.5452 - val_mae: 0.4773\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 25s 99ms/step - loss: 0.0262 - mae: 0.0926 - val_loss: 0.5686 - val_mae: 0.4684\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 23s 93ms/step - loss: 0.0277 - mae: 0.0986 - val_loss: 0.5508 - val_mae: 0.4721\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 25s 101ms/step - loss: 0.0294 - mae: 0.1022 - val_loss: 0.5399 - val_mae: 0.4645\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 27s 108ms/step - loss: 0.0258 - mae: 0.0930 - val_loss: 0.5753 - val_mae: 0.4851\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 23s 91ms/step - loss: 0.0257 - mae: 0.0970 - val_loss: 0.5700 - val_mae: 0.4828\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 25s 102ms/step - loss: 0.0236 - mae: 0.0875 - val_loss: 0.5658 - val_mae: 0.4631\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 24s 97ms/step - loss: 0.0271 - mae: 0.0957 - val_loss: 0.6199 - val_mae: 0.5049\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 25s 99ms/step - loss: 0.0272 - mae: 0.0950 - val_loss: 0.5765 - val_mae: 0.4924\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 25s 101ms/step - loss: 0.0256 - mae: 0.0932 - val_loss: 0.5806 - val_mae: 0.4826\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 23s 92ms/step - loss: 0.0229 - mae: 0.0847 - val_loss: 0.5548 - val_mae: 0.4603\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 26s 103ms/step - loss: 0.0204 - mae: 0.0777 - val_loss: 0.5922 - val_mae: 0.5194\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 23s 92ms/step - loss: 0.0258 - mae: 0.0922 - val_loss: 0.5529 - val_mae: 0.4900\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 25s 101ms/step - loss: 0.0183 - mae: 0.0753 - val_loss: 0.5610 - val_mae: 0.4743\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 24s 97ms/step - loss: 0.0162 - mae: 0.0674 - val_loss: 0.5487 - val_mae: 0.4557\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 24s 94ms/step - loss: 0.0162 - mae: 0.0695 - val_loss: 0.5785 - val_mae: 0.4642\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 28s 111ms/step - loss: 0.0194 - mae: 0.0779 - val_loss: 0.6110 - val_mae: 0.4850\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 24s 94ms/step - loss: 0.0314 - mae: 0.1061 - val_loss: 0.5719 - val_mae: 0.4590\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 25s 100ms/step - loss: 0.0264 - mae: 0.0918 - val_loss: 0.5488 - val_mae: 0.4599\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 28s 111ms/step - loss: 0.0197 - mae: 0.0778 - val_loss: 0.5637 - val_mae: 0.4726\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 27s 108ms/step - loss: 0.0184 - mae: 0.0751 - val_loss: 0.5479 - val_mae: 0.4694\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 26s 104ms/step - loss: 0.0220 - mae: 0.0853 - val_loss: 0.5683 - val_mae: 0.4641\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 28s 112ms/step - loss: 0.0202 - mae: 0.0785 - val_loss: 0.6119 - val_mae: 0.4784\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 28s 112ms/step - loss: 0.0179 - mae: 0.0730 - val_loss: 0.5653 - val_mae: 0.4921\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 26s 106ms/step - loss: 0.0177 - mae: 0.0731 - val_loss: 0.5828 - val_mae: 0.4617\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 27s 106ms/step - loss: 0.0229 - mae: 0.0886 - val_loss: 0.5546 - val_mae: 0.4627\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 28s 110ms/step - loss: 0.0203 - mae: 0.0777 - val_loss: 0.5588 - val_mae: 0.4573\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 29s 117ms/step - loss: 0.0181 - mae: 0.0710 - val_loss: 0.5737 - val_mae: 0.4800\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 26s 106ms/step - loss: 0.0158 - mae: 0.0665 - val_loss: 0.5661 - val_mae: 0.4841\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 27s 109ms/step - loss: 0.0138 - mae: 0.0620 - val_loss: 0.6162 - val_mae: 0.5047\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 28s 113ms/step - loss: 0.0184 - mae: 0.0732 - val_loss: 0.5627 - val_mae: 0.4808\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 30s 120ms/step - loss: 0.0182 - mae: 0.0736 - val_loss: 0.5759 - val_mae: 0.4927\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 28s 113ms/step - loss: 0.0167 - mae: 0.0687 - val_loss: 0.5841 - val_mae: 0.4792\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 25s 101ms/step - loss: 0.0263 - mae: 0.0882 - val_loss: 0.5758 - val_mae: 0.4718\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 27s 108ms/step - loss: 0.0246 - mae: 0.0861 - val_loss: 0.5724 - val_mae: 0.4659\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 28s 112ms/step - loss: 0.0193 - mae: 0.0732 - val_loss: 0.5827 - val_mae: 0.4680\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 29s 114ms/step - loss: 0.0351 - mae: 0.0796 - val_loss: 0.5580 - val_mae: 0.4669\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 28s 113ms/step - loss: 0.0137 - mae: 0.0625 - val_loss: 0.5662 - val_mae: 0.4659\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 25s 101ms/step - loss: 0.0126 - mae: 0.0561 - val_loss: 0.5899 - val_mae: 0.4775\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 28s 112ms/step - loss: 0.0297 - mae: 0.0976 - val_loss: 0.5882 - val_mae: 0.4767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "predictions = model.predict({'text_input': text_sequences, 'title_input': title_sequences})\n",
        "\n",
        "# Round the predictions to the nearest integer\n",
        "rounded_predictions = np.rint(predictions).astype(int).flatten()\n",
        "\n",
        "# Calculate the percentage of values where the rounded prediction equals the actual rating\n",
        "correct_predictions = rounded_predictions == df['rating'].values\n",
        "accuracy = np.mean(correct_predictions)\n",
        "\n",
        "print(f\"Percentage of values where rounded prediction equals actual rating: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbD_1huOBmK9",
        "outputId": "64533110-6d90-4073-8a1e-b98513276773"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 12s 34ms/step\n",
            "Percentage of values where rounded prediction equals actual rating: 90.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of values where the rounded prediction equals the actual rating\n",
        "correct_predictions = rounded_predictions -1 == df['rating'].values\n",
        "accuracy = np.mean(correct_predictions)\n",
        "\n",
        "print(f\"Percentage of values where rounded prediction equals actual rating: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEZkZr98CK_g",
        "outputId": "7ae14dad-c320-4482-fb3b-986d05199f34"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 12s 39ms/step\n",
            "Percentage of values where rounded prediction equals actual rating: 4.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Embed the inputs\n",
        "text_embedding = embedding_layer_text(text_input)\n",
        "title_embedding = embedding_layer_title(title_input)\n",
        "\n",
        "# Define Bidirectional LSTM layers with dropout\n",
        "text_lstm = Bidirectional(LSTM(64, return_sequences=True))(text_embedding)\n",
        "text_lstm = Bidirectional(LSTM(32))(text_lstm)\n",
        "text_lstm = Dropout(0.3)(text_lstm)\n",
        "\n",
        "title_lstm = Bidirectional(LSTM(32))(title_embedding)\n",
        "title_lstm = Dropout(0.3)(title_lstm)\n",
        "\n",
        "# Concatenate the LSTM outputs\n",
        "concat = Concatenate()([text_lstm, title_lstm])\n",
        "\n",
        "# Add dense layers with dropout and L2 regularization\n",
        "dense = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(concat)\n",
        "dense = Dropout(0.3)(dense)\n",
        "dense = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(dense)\n",
        "dense = Dropout(0.3)(dense)\n",
        "\n",
        "output = Dense(1, activation='linear')(dense)  # Assuming regression for ratings\n",
        "\n",
        "# Create the model\n",
        "# model = Model(inputs=[text_input, title_input], outputs=output)\n",
        "# model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# # Summary of the model\n",
        "# model.summary()\n",
        "\n",
        "# # Add early stopping\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# # Train the model\n",
        "# history = model.fit(\n",
        "#     {'text_input': text_sequences, 'title_input': title_sequences},\n",
        "#     df['rating'],\n",
        "#     epochs=100,\n",
        "#     batch_size=32,\n",
        "#     validation_split=0.2,\n",
        "#     callbacks=[early_stopping]\n",
        "# )\n",
        "# Create the model\n",
        "model = Model(inputs=[text_input, title_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "history = model.fit({'text_input': text_sequences, 'title_input': title_sequences}, df['rating'], epochs=100, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmhnqUidLWV-",
        "outputId": "d59104ff-6184-4daf-8d1f-c7065ab750db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text_input (InputLayer)     [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)     (None, 100, 100)             1759100   ['text_input[0][0]']          \n",
            "                                                                                                  \n",
            " title_input (InputLayer)    [(None, 20)]                 0         []                            \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirecti  (None, 100, 128)             84480     ['embedding_7[1][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " embedding_8 (Embedding)     (None, 20, 100)              1759100   ['title_input[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirecti  (None, 64)                   41216     ['bidirectional_3[0][0]']     \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " bidirectional_5 (Bidirecti  (None, 64)                   34048     ['embedding_8[1][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 64)                   0         ['bidirectional_4[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 64)                   0         ['bidirectional_5[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 128)                  0         ['dropout_11[0][0]',          \n",
            " e)                                                                  'dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " dense_21 (Dense)            (None, 64)                   8256      ['concatenate_11[0][0]']      \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 64)                   0         ['dense_21[0][0]']            \n",
            "                                                                                                  \n",
            " dense_22 (Dense)            (None, 32)                   2080      ['dropout_13[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 32)                   0         ['dense_22[0][0]']            \n",
            "                                                                                                  \n",
            " dense_23 (Dense)            (None, 1)                    33        ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3688313 (14.07 MB)\n",
            "Trainable params: 170113 (664.50 KB)\n",
            "Non-trainable params: 3518200 (13.42 MB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "250/250 [==============================] - 17s 30ms/step - loss: 3.9054 - mae: 1.3686 - val_loss: 1.3472 - val_mae: 0.6416\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 2.0408 - mae: 0.9734 - val_loss: 1.1291 - val_mae: 0.6105\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 1.6113 - mae: 0.8805 - val_loss: 0.9096 - val_mae: 0.6289\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 1.3516 - mae: 0.8164 - val_loss: 0.7847 - val_mae: 0.5931\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 1.2350 - mae: 0.8001 - val_loss: 0.8356 - val_mae: 0.6802\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 1.1175 - mae: 0.7729 - val_loss: 0.6475 - val_mae: 0.5649\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.9911 - mae: 0.7299 - val_loss: 0.7258 - val_mae: 0.6549\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.9459 - mae: 0.7284 - val_loss: 0.5582 - val_mae: 0.5213\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 6s 24ms/step - loss: 0.8786 - mae: 0.7017 - val_loss: 0.6625 - val_mae: 0.6473\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.8251 - mae: 0.6849 - val_loss: 0.5334 - val_mae: 0.5040\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.7721 - mae: 0.6591 - val_loss: 0.6106 - val_mae: 0.5953\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.7338 - mae: 0.6510 - val_loss: 0.5496 - val_mae: 0.5180\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 0.6860 - mae: 0.6313 - val_loss: 0.4908 - val_mae: 0.4859\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.6623 - mae: 0.6191 - val_loss: 0.5603 - val_mae: 0.5086\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.6203 - mae: 0.6036 - val_loss: 0.5229 - val_mae: 0.5005\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 6s 23ms/step - loss: 0.5654 - mae: 0.5715 - val_loss: 0.5318 - val_mae: 0.5128\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.5728 - mae: 0.5791 - val_loss: 0.5118 - val_mae: 0.5165\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 0.5441 - mae: 0.5671 - val_loss: 0.5306 - val_mae: 0.5109\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.5281 - mae: 0.5626 - val_loss: 0.6563 - val_mae: 0.5863\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4954 - mae: 0.5458 - val_loss: 0.5514 - val_mae: 0.5504\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.4998 - mae: 0.5508 - val_loss: 0.5009 - val_mae: 0.4884\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4755 - mae: 0.5395 - val_loss: 0.5091 - val_mae: 0.4886\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 5s 21ms/step - loss: 0.4785 - mae: 0.5428 - val_loss: 0.5502 - val_mae: 0.5239\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 6s 24ms/step - loss: 0.4829 - mae: 0.5456 - val_loss: 0.5639 - val_mae: 0.5334\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.4566 - mae: 0.5301 - val_loss: 0.5498 - val_mae: 0.5234\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.4413 - mae: 0.5255 - val_loss: 0.5875 - val_mae: 0.5111\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 0.4309 - mae: 0.5173 - val_loss: 0.5192 - val_mae: 0.5157\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.4341 - mae: 0.5198 - val_loss: 0.5421 - val_mae: 0.5215\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 0.4364 - mae: 0.5227 - val_loss: 0.5644 - val_mae: 0.5254\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.4184 - mae: 0.5112 - val_loss: 0.5261 - val_mae: 0.4940\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4196 - mae: 0.5155 - val_loss: 0.5711 - val_mae: 0.5209\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.4053 - mae: 0.5036 - val_loss: 0.5411 - val_mae: 0.5187\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 6s 23ms/step - loss: 0.4576 - mae: 0.5328 - val_loss: 0.5687 - val_mae: 0.5344\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.4350 - mae: 0.5224 - val_loss: 0.5454 - val_mae: 0.5502\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.4032 - mae: 0.5008 - val_loss: 0.5423 - val_mae: 0.5028\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4033 - mae: 0.5017 - val_loss: 0.5520 - val_mae: 0.5093\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3897 - mae: 0.4932 - val_loss: 0.5339 - val_mae: 0.5181\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3879 - mae: 0.4925 - val_loss: 0.5072 - val_mae: 0.4910\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3897 - mae: 0.4954 - val_loss: 0.6031 - val_mae: 0.5664\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 0.4064 - mae: 0.5054 - val_loss: 0.5315 - val_mae: 0.5318\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 6s 23ms/step - loss: 0.3863 - mae: 0.4945 - val_loss: 0.5355 - val_mae: 0.5194\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3927 - mae: 0.4947 - val_loss: 0.5584 - val_mae: 0.4996\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 0.3836 - mae: 0.4912 - val_loss: 0.5609 - val_mae: 0.5256\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3766 - mae: 0.4854 - val_loss: 0.5518 - val_mae: 0.5234\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3785 - mae: 0.4873 - val_loss: 0.6040 - val_mae: 0.5491\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3670 - mae: 0.4782 - val_loss: 0.6280 - val_mae: 0.5305\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.3685 - mae: 0.4755 - val_loss: 0.5769 - val_mae: 0.5830\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3670 - mae: 0.4791 - val_loss: 0.5626 - val_mae: 0.5556\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.3741 - mae: 0.4850 - val_loss: 0.5493 - val_mae: 0.5539\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.3641 - mae: 0.4784 - val_loss: 0.5929 - val_mae: 0.5697\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3609 - mae: 0.4760 - val_loss: 0.5311 - val_mae: 0.5420\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3687 - mae: 0.4803 - val_loss: 0.5486 - val_mae: 0.5093\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3623 - mae: 0.4758 - val_loss: 0.5652 - val_mae: 0.5771\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 0.3604 - mae: 0.4753 - val_loss: 0.5478 - val_mae: 0.5348\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3585 - mae: 0.4736 - val_loss: 0.5430 - val_mae: 0.5018\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 6s 26ms/step - loss: 0.3626 - mae: 0.4781 - val_loss: 0.5812 - val_mae: 0.5754\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 6s 23ms/step - loss: 0.3545 - mae: 0.4724 - val_loss: 0.5609 - val_mae: 0.5068\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3489 - mae: 0.4670 - val_loss: 0.6725 - val_mae: 0.5847\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3544 - mae: 0.4712 - val_loss: 0.5712 - val_mae: 0.5300\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3641 - mae: 0.4788 - val_loss: 0.5415 - val_mae: 0.5003\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3483 - mae: 0.4685 - val_loss: 0.5563 - val_mae: 0.5281\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3489 - mae: 0.4675 - val_loss: 0.5590 - val_mae: 0.5823\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.3510 - mae: 0.4686 - val_loss: 0.5486 - val_mae: 0.5139\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3555 - mae: 0.4724 - val_loss: 0.5467 - val_mae: 0.5017\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 6s 26ms/step - loss: 0.3537 - mae: 0.4740 - val_loss: 0.6149 - val_mae: 0.5865\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 6s 23ms/step - loss: 0.3606 - mae: 0.4771 - val_loss: 0.5968 - val_mae: 0.5196\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3491 - mae: 0.4673 - val_loss: 0.5792 - val_mae: 0.5352\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 0.3418 - mae: 0.4636 - val_loss: 0.5482 - val_mae: 0.5154\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3415 - mae: 0.4636 - val_loss: 0.5650 - val_mae: 0.5251\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3379 - mae: 0.4602 - val_loss: 0.5422 - val_mae: 0.4955\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3253 - mae: 0.4507 - val_loss: 0.5390 - val_mae: 0.5061\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3361 - mae: 0.4586 - val_loss: 0.5708 - val_mae: 0.5413\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3536 - mae: 0.4702 - val_loss: 0.5716 - val_mae: 0.5015\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 6s 24ms/step - loss: 0.3399 - mae: 0.4618 - val_loss: 0.5674 - val_mae: 0.5318\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 7s 26ms/step - loss: 0.3377 - mae: 0.4599 - val_loss: 0.5237 - val_mae: 0.5230\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3317 - mae: 0.4570 - val_loss: 0.5755 - val_mae: 0.5158\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3263 - mae: 0.4525 - val_loss: 0.5729 - val_mae: 0.5265\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3306 - mae: 0.4544 - val_loss: 0.5654 - val_mae: 0.5173\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3353 - mae: 0.4579 - val_loss: 0.5575 - val_mae: 0.5029\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 6s 23ms/step - loss: 0.3264 - mae: 0.4527 - val_loss: 0.5619 - val_mae: 0.5562\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.3375 - mae: 0.4612 - val_loss: 0.6140 - val_mae: 0.5402\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3299 - mae: 0.4535 - val_loss: 0.5632 - val_mae: 0.5039\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 6s 24ms/step - loss: 0.3361 - mae: 0.4614 - val_loss: 0.6716 - val_mae: 0.5500\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 6s 26ms/step - loss: 0.3448 - mae: 0.4657 - val_loss: 0.5642 - val_mae: 0.5472\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3377 - mae: 0.4588 - val_loss: 0.5468 - val_mae: 0.5134\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3339 - mae: 0.4569 - val_loss: 0.6458 - val_mae: 0.6003\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3276 - mae: 0.4515 - val_loss: 0.5631 - val_mae: 0.5056\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3243 - mae: 0.4492 - val_loss: 0.5765 - val_mae: 0.4924\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 6s 23ms/step - loss: 0.3927 - mae: 0.4865 - val_loss: 0.6744 - val_mae: 0.5379\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4383 - mae: 0.5196 - val_loss: 0.6113 - val_mae: 0.5337\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3786 - mae: 0.4866 - val_loss: 0.6152 - val_mae: 0.5284\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 6s 24ms/step - loss: 0.3406 - mae: 0.4598 - val_loss: 0.6370 - val_mae: 0.5896\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.3355 - mae: 0.4561 - val_loss: 0.6224 - val_mae: 0.5716\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.3319 - mae: 0.4561 - val_loss: 0.5919 - val_mae: 0.4956\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3258 - mae: 0.4526 - val_loss: 0.5867 - val_mae: 0.5591\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.3232 - mae: 0.4508 - val_loss: 0.5881 - val_mae: 0.5484\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.3279 - mae: 0.4503 - val_loss: 0.6324 - val_mae: 0.5874\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 6s 23ms/step - loss: 0.3185 - mae: 0.4449 - val_loss: 0.6106 - val_mae: 0.5254\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.3232 - mae: 0.4496 - val_loss: 0.6604 - val_mae: 0.5499\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 6s 24ms/step - loss: 0.3120 - mae: 0.4397 - val_loss: 0.5835 - val_mae: 0.5084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Ino2Hn318FPn",
        "outputId": "3f3995cb-72d2-47a9-dbac-b43c9ed473f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define new review data\n",
        "new_reviews = [\n",
        "    {'text': 'The flight was very comfortable and the staff were extremely friendly.', 'title': 'Great '},\n",
        "    {'text': 'Attendants were the worst and the flight was also late', 'title': 'I will never travel in this flight again'}\n",
        "]\n",
        "\n",
        "# Preprocess the new review data\n",
        "new_reviews_df = pd.DataFrame(new_reviews)\n",
        "new_reviews_df['cleaned_text'] = new_reviews_df['text'].apply(preprocess_text)\n",
        "new_reviews_df['cleaned_title'] = new_reviews_df['title'].apply(preprocess_text)\n",
        "\n",
        "new_text_sequences = prepare_text(new_reviews_df, 'cleaned_text', tokenizer, max_length_text)\n",
        "new_title_sequences = prepare_text(new_reviews_df, 'cleaned_title', tokenizer, max_length_title)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict({'text_input': new_text_sequences, 'title_input': new_title_sequences})\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaJlF_v18i5X",
        "outputId": "456e3171-5a32-4fe5-cbd1-722d53a5b347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "[[5.145838 ]\n",
            " [1.6227101]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define new review data\n",
        "new_reviews = [\n",
        "    {'text': 'The airplane was ok', 'title': 'Forgetfull Flight'}\n",
        "]\n",
        "\n",
        "# Preprocess the new review data\n",
        "new_reviews_df = pd.DataFrame(new_reviews)\n",
        "new_reviews_df['cleaned_text'] = new_reviews_df['text'].apply(preprocess_text)\n",
        "new_reviews_df['cleaned_title'] = new_reviews_df['title'].apply(preprocess_text)\n",
        "\n",
        "new_text_sequences = prepare_text(new_reviews_df, 'cleaned_text', tokenizer, max_length_text)\n",
        "new_title_sequences = prepare_text(new_reviews_df, 'cleaned_title', tokenizer, max_length_title)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict({'text_input': new_text_sequences, 'title_input': new_title_sequences})\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdTaIuj38-Mw",
        "outputId": "02ad0163-8cb1-4e89-d049-4f488190ff94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "[[3.4369547]]\n"
          ]
        }
      ]
    }
  ]
}